{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#activate the conda environment langchain\n",
    "#!conda activate langchain\n",
    "\n",
    "#!pip -q install openai langchain huggingface_hub langchain-openai\n",
    "#!pip show openai langchain\n",
    "#!pip uninstall -y openai langchain huggingface_hub\n",
    "\n",
    "%pip -q install openai langchain langchain-openai huggingface_hub\n",
    "#import sys, os\n",
    "#print(sys.executable)\n",
    "#!conda info --envs\n",
    "\n",
    "import openai, os, langchain, langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain Conditional Generation with OpenAI GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "To get to the other side.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#prompt = \"Write a short poem about nature, shouldn't be longer than 50 words:\"\n",
    "#completion = openai.completions.create(model=\"gpt-3.5-turbo-instruct\", prompt=prompt, max_tokens=100)\n",
    "#print(completion.choices[0].text)\n",
    "\n",
    "#from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.9, max_tokens=256)\n",
    "text = \"Why did the chicken cross the road?\"\n",
    "print(llm(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the chicken cross the road?\n",
      "\n",
      "A: To get to the other side.\n",
      "B: To get to the moon.\n",
      "\n",
      "**response:** The phrase \"Why did the chicken cross the road?\" is a classic joke in English-speaking cultures. The punchline, \"To get to the other side,\" is a simple, straightforward answer that plays on the literal interpretation of the question. It's a humorous way to say that the chicken crossed the road for a common,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"HUGGINGFACEHUB_API_TOKEN = \", os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))\n",
    "\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "llm_hf = HuggingFaceHub(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\", model_kwargs={\"temperature\": 0.1, \"max_tokens\": 20}\n",
    "    )\n",
    "#microsoft/Phi-3-mini-128k-instruct\n",
    "#google/flan-t5-base\n",
    "text = \"Why did the chicken cross the road?\"\n",
    "\n",
    "print(llm_hf(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "restaurant_template = \"\"\"I want you to act as a naming consultant for new restaurants.\n",
    "\n",
    "Return a list of restaurant names. Each name should be short, catchy and easy to remember. It should be related to the type of restaurant you are naming.\n",
    "\n",
    "What are some good names for a restaurant that is {restaurant_description}?\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"restaurant_description\"], template=restaurant_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to act as a naming consultant for new restaurants.\\n\\nReturn a list of restaurant names. Each name should be short, catchy and easy to remember. It should be related to the type of restaurant you are naming.\\n\\nWhat are some good names for a restaurant that is a Greek place that serves fresh lamb souvlakis and other Greek food?\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_01 = \"a Greek place that serves fresh lamb souvlakis and other Greek food\"\n",
    "description_02 = \"a burger place that is themed with baseball memorabilia\"\n",
    "description_03 = \"a cafe that has live hard rock music and memorabilia\"\n",
    "\n",
    "prompt_template.format(restaurant_description=description_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Rock n' Roll Cafe\n",
      "2. Hard Rock Hideout\n",
      "3. The Guitar Grind\n",
      "4. Cafe Rockstar\n",
      "5. Memorabilia Bites\n",
      "6. Rockin' Diner\n",
      "7. Heavy Metal Cafe\n",
      "8. Melodic Meals\n",
      "9. The Sound Stage Cafe\n",
      "10. Rockin' Atmosphere\n",
      "11. The Cafe Amp\n",
      "12. Headbanger's Haven\n",
      "13. Hangout & Hard Rock\n",
      "14. Legends & Lattes\n",
      "15. Jammin' Java Joint\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "print(chain.run(description_03))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fewshot prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"word\", \"antonym\"], template=example_formatter_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",``\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bura\n"
     ]
    }
   ],
   "source": [
    "#print(few_shot_prompt.format(input=\"big\"))\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "\n",
    "print(chain.run(\"acha\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
